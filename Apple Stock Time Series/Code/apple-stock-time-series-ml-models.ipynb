{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T20:17:30.714107Z","iopub.execute_input":"2022-03-10T20:17:30.714962Z","iopub.status.idle":"2022-03-10T20:17:31.738097Z","shell.execute_reply.started":"2022-03-10T20:17:30.714834Z","shell.execute_reply":"2022-03-10T20:17:31.737183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    figsize=(11, 4),\n    titlesize=18,\n    titleweight='bold',\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\n%config InlineBackend.figure_format = 'retina'","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:18:14.188866Z","iopub.execute_input":"2022-03-10T20:18:14.189819Z","iopub.status.idle":"2022-03-10T20:18:14.208291Z","shell.execute_reply.started":"2022-03-10T20:18:14.189765Z","shell.execute_reply":"2022-03-10T20:18:14.207599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load Apple data\napple = pd.read_csv('../input/stock-time-series-20050101-to-20171231/AAPL_2006-01-01_to_2018-01-01.csv', index_col=\"Date\", parse_dates=[\"Date\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:18:34.017979Z","iopub.execute_input":"2022-03-10T20:18:34.018282Z","iopub.status.idle":"2022-03-10T20:18:34.052879Z","shell.execute_reply.started":"2022-03-10T20:18:34.018248Z","shell.execute_reply":"2022-03-10T20:18:34.052019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apple.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:18:42.188761Z","iopub.execute_input":"2022-03-10T20:18:42.189033Z","iopub.status.idle":"2022-03-10T20:18:42.210737Z","shell.execute_reply.started":"2022-03-10T20:18:42.189001Z","shell.execute_reply":"2022-03-10T20:18:42.20963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apple.tail()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:18:45.543913Z","iopub.execute_input":"2022-03-10T20:18:45.544177Z","iopub.status.idle":"2022-03-10T20:18:45.558118Z","shell.execute_reply.started":"2022-03-10T20:18:45.544146Z","shell.execute_reply":"2022-03-10T20:18:45.557528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Context: \n\nDate - in format: yy-mm-dd\n\nOpen - price of the stock at market open (this is NYSE data so all in USD)\n\nHigh - Highest price reached in the day\n\nLow Close - Lowest price reached in the day\n\nVolume - Number of shares traded\n\nName - the stock's ticker name","metadata":{}},{"cell_type":"code","source":"apple.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:19:08.119921Z","iopub.execute_input":"2022-03-10T20:19:08.120388Z","iopub.status.idle":"2022-03-10T20:19:08.125829Z","shell.execute_reply.started":"2022-03-10T20:19:08.120355Z","shell.execute_reply":"2022-03-10T20:19:08.125034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apple.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:19:10.540893Z","iopub.execute_input":"2022-03-10T20:19:10.541177Z","iopub.status.idle":"2022-03-10T20:19:10.563741Z","shell.execute_reply.started":"2022-03-10T20:19:10.541144Z","shell.execute_reply":"2022-03-10T20:19:10.563058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apple.plot(subplots=True, figsize=(10, 15))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:19:16.390701Z","iopub.execute_input":"2022-03-10T20:19:16.391334Z","iopub.status.idle":"2022-03-10T20:19:18.433192Z","shell.execute_reply.started":"2022-03-10T20:19:16.391299Z","shell.execute_reply":"2022-03-10T20:19:18.43223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# .asfreq( ) does change the size of series\n# Converts time series to specified frequency.\n# Returns the original data conformed to a new index with the specified frequency\napple[\"Close\"].asfreq('M').interpolate().plot(legend=True)\nshifted = apple[\"Close\"].asfreq('M').interpolate().shift(10).plot(legend=True)\nplt.legend(['Close','Close_lagged'])\nplt.title('Closing price of Apple over time (Monthly frequency) - raw and lagged')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:19:59.969012Z","iopub.execute_input":"2022-03-10T20:19:59.969641Z","iopub.status.idle":"2022-03-10T20:20:00.327463Z","shell.execute_reply.started":"2022-03-10T20:19:59.969593Z","shell.execute_reply":"2022-03-10T20:20:00.326886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Resampling time series:**\n\nUndersampling - Time series is resampled from high frequency to low frequency (here weekly to monthly frequency). It needs aggregation.\n\nOversampling - Time series is resampled from low frequency to high frequency (here daily to hourly frequency). It needs filling or interpolating missing data\n\n","metadata":{}},{"cell_type":"code","source":"# Undersampling (decreases the size of series)\nprint(apple.shape[0])\nprint(apple.resample('M').mean().shape[0])\n(apple.resample('M').mean())[\"Close\"].plot()\nplt.title(\"'Closing price of Apple over time (Monthly frequency) - undersampled'\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:20:34.574874Z","iopub.execute_input":"2022-03-10T20:20:34.575279Z","iopub.status.idle":"2022-03-10T20:20:34.958702Z","shell.execute_reply.started":"2022-03-10T20:20:34.575249Z","shell.execute_reply":"2022-03-10T20:20:34.957966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Oversampling (increases the size of series)\napple.resample(\"H\").fillna(method=\"ffill\")\n\n#apple.resample(\"H\").fillna(method=\"bfill\")\n\n# apple.resample(\"H\").interpolate( )","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:21:12.055639Z","iopub.execute_input":"2022-03-10T20:21:12.055895Z","iopub.status.idle":"2022-03-10T20:21:12.081523Z","shell.execute_reply.started":"2022-03-10T20:21:12.055868Z","shell.execute_reply":"2022-03-10T20:21:12.080687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Window functions:**\n\nRolling - Same size and sliding\n\nExpanding - Contains all prior values","metadata":{}},{"cell_type":"markdown","source":"**Moving average plots to discover the trend in a series:**","metadata":{}},{"cell_type":"code","source":"# rolling does not change the size of series\nprint(apple.shape[0])\nprint(apple[\"Close\"].rolling(window = 30).mean().shape)\napple[\"Close\"].plot()\napple[\"Close\"].rolling(window = 30).mean().plot()\nplt.legend([\"Close\", \"Rolling Mean\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:21:40.825664Z","iopub.execute_input":"2022-03-10T20:21:40.826414Z","iopub.status.idle":"2022-03-10T20:21:41.494426Z","shell.execute_reply.started":"2022-03-10T20:21:40.826364Z","shell.execute_reply":"2022-03-10T20:21:41.493586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving average plot of apple[\"Close\"]\napple[\"Close\"].plot()\n#apple[\"Close\"].rolling(window = \"180D\").mean().plot()\nmoving_average = apple[\"Close\"].rolling(\n    window=360,       # 180-day window\n    center=True,      # puts the average at the center of the window\n    min_periods=180,  # choose about half the window size\n).mean()              # compute the mean (could also do median, std, min, max, ...)\nmoving_average.plot()\nplt.legend([\"Close\", \"Moving average\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:22:03.741985Z","iopub.execute_input":"2022-03-10T20:22:03.742278Z","iopub.status.idle":"2022-03-10T20:22:04.26419Z","shell.execute_reply.started":"2022-03-10T20:22:03.742245Z","shell.execute_reply":"2022-03-10T20:22:04.26336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving average plot of apple[\"Volume\"]\napple[\"Volume\"].plot()\n#apple[\"Close\"].rolling(window = \"180D\").mean().plot()\nmoving_average = apple[\"Volume\"].rolling(\n    window=360,       # 180-day window\n    center=True,      # puts the average at the center of the window\n    min_periods=180,  # choose about half the window size\n).mean()              # compute the mean (could also do median, std, min, max, ...)\nmoving_average.plot()\nplt.legend([\"Volume\", \"Moving average\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:22:28.199684Z","iopub.execute_input":"2022-03-10T20:22:28.199977Z","iopub.status.idle":"2022-03-10T20:22:28.706137Z","shell.execute_reply.started":"2022-03-10T20:22:28.199936Z","shell.execute_reply":"2022-03-10T20:22:28.70524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Autocorrelation and Partial Autocorrelation:**","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:22:53.752758Z","iopub.execute_input":"2022-03-10T20:22:53.753042Z","iopub.status.idle":"2022-03-10T20:22:53.932986Z","shell.execute_reply.started":"2022-03-10T20:22:53.753005Z","shell.execute_reply":"2022-03-10T20:22:53.932312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most commonly used measure of serial dependence is known as autocorrelation, which is the correlation a time series has with one of its lags.","metadata":{}},{"cell_type":"code","source":"# Autocorrelation of Closing price of Apple\nplot_acf(apple[\"Close\"],lags=20,title=\"Autocorrelation chart: Apple (Close price)\")\nplot_acf(apple[\"Volume\"],lags=20,title=\"Autocorrelation chart: Apple (Volume)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:23:30.226917Z","iopub.execute_input":"2022-03-10T20:23:30.227202Z","iopub.status.idle":"2022-03-10T20:23:30.813545Z","shell.execute_reply.started":"2022-03-10T20:23:30.227172Z","shell.execute_reply":"2022-03-10T20:23:30.812513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All lags are greater than the confidence interval, so they are statistically significant.","metadata":{}},{"cell_type":"markdown","source":" The **partial autocorrelation** tells you the correlation of a lag **accounting for all of the previous lags**, i.e., the amount of \"new\" correlation the lag contributes.\n","metadata":{}},{"cell_type":"code","source":"# Partial Autocorrelation of Closing price of Apple\n_ = plot_pacf(apple[\"Close\"],lags=20, title=\"Partial autocorrelation of Apple (Close price) with 95% confidence intervals of no correlation.\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Partial autocorrelation after first lag is very low.\n\nNote taht autocorrelation and partial autocorrelation are measures of linear dependence. Because time series may have non-linear dependences, we need to look at a lag plot (or a more general measure of dependence, like mutual information) when choosing lag features.\n\n","metadata":{}},{"cell_type":"code","source":"# the 2 follwing functions taken from https://www.kaggle.com/ryanholbrook/time-series-as-features\n\ndef lagplot(x, y=None, lag=1, standardize=False, ax=None, **kwargs):\n    from matplotlib.offsetbox import AnchoredText\n    x_ = x.shift(lag)\n    if standardize:\n        x_ = (x_ - x_.mean()) / x_.std()\n    if y is not None:\n        y_ = (y - y.mean()) / y.std() if standardize else y\n    else:\n        y_ = x\n    corr = y_.corr(x_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    scatter_kws = dict(\n        alpha=0.75,\n        s=3,\n    )\n    line_kws = dict(color='C3', )\n    ax = sns.regplot(x=x_,\n                     y=y_,\n                     scatter_kws=scatter_kws,\n                     line_kws=line_kws,\n                     lowess=True,\n                     ax=ax,\n                     **kwargs)\n    at = AnchoredText(\n        f\"{corr:.2f}\",\n        prop=dict(size=\"large\"),\n        frameon=True,\n        loc=\"upper left\",\n    )\n    at.patch.set_boxstyle(\"square, pad=0.0\")\n    ax.add_artist(at)\n    ax.set(title=f\"Lag {lag}\", xlabel=x_.name, ylabel=y_.name)\n    return ax\n\n\n\ndef plot_lags(x, y=None, lags=6, nrows=1, lagplot_kwargs={}, **kwargs):\n    import math\n    kwargs.setdefault('nrows', nrows)\n    kwargs.setdefault('ncols', math.ceil(lags / nrows))\n    kwargs.setdefault('figsize', (kwargs['ncols'] * 2, nrows * 2 + 0.5))\n    fig, axs = plt.subplots(sharex=True, sharey=True, squeeze=False, **kwargs)\n    for ax, k in zip(fig.get_axes(), range(kwargs['nrows'] * kwargs['ncols'])):\n        if k + 1 <= lags:\n            ax = lagplot(x, y, lag=k + 1, ax=ax, **lagplot_kwargs)\n            ax.set_title(f\"Lag {k + 1}\", fontdict=dict(fontsize=14))\n            ax.set(xlabel=\"\", ylabel=\"\")\n        else:\n            ax.axis('off')\n    plt.setp(axs[-1, :], xlabel=x.name)\n    plt.setp(axs[:, 0], ylabel=y.name if y is not None else x.name)\n    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n    return fig\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:24:06.625687Z","iopub.execute_input":"2022-03-10T20:24:06.625985Z","iopub.status.idle":"2022-03-10T20:24:06.639949Z","shell.execute_reply.started":"2022-03-10T20:24:06.625954Z","shell.execute_reply":"2022-03-10T20:24:06.638968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A lag plot of a time series shows its values plotted against its lags\n_ = plot_lags(apple[\"Close\"], lags=20, nrows=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The lag plots indicate that the relationship of apple[\"Close\"] to its lags is linear, while the partial autocorrelations suggest the dependence can be captured using lags 1.","metadata":{}},{"cell_type":"code","source":"# Partial Autocorrelation of Volume of Apple\n_ = plot_pacf(apple[\"Volume\"],lags=20, title=\"Partial autocorrelation of Apple (Volume) with 95% confidence intervals of no correlation.\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:24:39.812336Z","iopub.execute_input":"2022-03-10T20:24:39.812637Z","iopub.status.idle":"2022-03-10T20:24:40.123187Z","shell.execute_reply.started":"2022-03-10T20:24:39.812606Z","shell.execute_reply":"2022-03-10T20:24:40.122361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Partial autocorrelation after 11th lag is very low.\n\nNote taht partial autocorrelation are measures of linear dependence. Because time series may have non-linear dependences, we need to look at a lag plot (or a more general measure of dependence, like mutual information) when choosing lag features.","metadata":{}},{"cell_type":"code","source":"# A lag plot of a time series shows its values plotted against its lags\n_ = plot_lags(apple[\"Volume\"], lags=20, nrows=3)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:24:56.984536Z","iopub.execute_input":"2022-03-10T20:24:56.985091Z","iopub.status.idle":"2022-03-10T20:25:10.892282Z","shell.execute_reply.started":"2022-03-10T20:24:56.985055Z","shell.execute_reply":"2022-03-10T20:25:10.891474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Choosing lags as features for ML models:**","metadata":{}},{"cell_type":"code","source":"# Use lags as features for ML models\n\ndef make_lags(ts, lags):\n    return pd.concat(\n        {\n            f'y_lag_{i}': ts.shift(i)\n            for i in range(1, lags + 1)\n        },\n        axis=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:27:08.684721Z","iopub.execute_input":"2022-03-10T20:27:08.684985Z","iopub.status.idle":"2022-03-10T20:27:08.69053Z","shell.execute_reply.started":"2022-03-10T20:27:08.684959Z","shell.execute_reply":"2022-03-10T20:27:08.689455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import mean_squared_error as mse\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:28:45.091308Z","iopub.execute_input":"2022-03-10T20:28:45.0918Z","iopub.status.idle":"2022-03-10T20:28:45.686828Z","shell.execute_reply.started":"2022-03-10T20:28:45.091751Z","shell.execute_reply":"2022-03-10T20:28:45.685915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1. Linear Regression and Lag features for apple[\"Close\"]:**","metadata":{}},{"cell_type":"code","source":"# Create X and y for ML models to predict apple[\"Close\"] \nX = make_lags(apple[\"Close\"], lags=1)\nX = X.fillna(0.0)\ny = apple[\"Close\"].copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:33:00.022955Z","iopub.execute_input":"2022-03-10T20:33:00.023257Z","iopub.status.idle":"2022-03-10T20:33:00.030263Z","shell.execute_reply.started":"2022-03-10T20:33:00.023225Z","shell.execute_reply":"2022-03-10T20:33:00.029461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data splits\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Fit and predict\nmodel = LinearRegression()  # `fit_intercept=True` since we didn't use DeterministicProcess\nmodel.fit(X_train, y_train)\ny_pred = pd.Series(model.predict(X_train), index=y_train.index)\ny_fore = pd.Series(model.predict(X_test), index=y_test.index)\nprint(f'Model train accuracy: {model.score(X_train, y_train)*100:.3f}%')\nprint(f'Model test accuracy: {model.score(X_test, y_test)*100:.3f}%')\nprint(f'Model train MAE: {mae(y_pred,y_train):.3f}')\nprint(f'Model train RMSE: {mse(y_pred,y_train, squared=False):.3f}')\nprint(f'Model test MAE: {mae(y_fore,y_test):.3f}')\nprint(f'Model test RMSE: {mse(y_fore,y_test, squared=False):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:33:02.14008Z","iopub.execute_input":"2022-03-10T20:33:02.141154Z","iopub.status.idle":"2022-03-10T20:33:02.164331Z","shell.execute_reply.started":"2022-03-10T20:33:02.141108Z","shell.execute_reply":"2022-03-10T20:33:02.163538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:30:57.69103Z","iopub.execute_input":"2022-03-10T20:30:57.691741Z","iopub.status.idle":"2022-03-10T20:30:57.696333Z","shell.execute_reply.started":"2022-03-10T20:30:57.6917Z","shell.execute_reply":"2022-03-10T20:30:57.695304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.plot(**plot_params)\ny_test.plot(**plot_params)\ny_pred.plot( )\ny_fore.plot( )","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:31:00.130854Z","iopub.execute_input":"2022-03-10T20:31:00.131154Z","iopub.status.idle":"2022-03-10T20:31:00.670783Z","shell.execute_reply.started":"2022-03-10T20:31:00.131116Z","shell.execute_reply":"2022-03-10T20:31:00.669858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1. Linear Regression and Lag features for apple[\"Volume\"]:**","metadata":{}},{"cell_type":"code","source":"# Create X and y for ML models to predict apple[\"Volume\"] \nX1 = make_lags(apple[\"Volume\"], lags=11)\nX1 = X1.fillna(0.0)\n\nX2 = pd.DataFrame(apple[\"Volume\"].shift(13)).rename(columns={\"Volume\":\"y_lag_13\"})\nX2 = X2.fillna(0.0)\n\nX3 = pd.DataFrame(apple[\"Volume\"].shift(15)).rename(columns={\"Volume\":\"y_lag_15\"})\nX3 = X3.fillna(0.0)\n\nX4 = pd.DataFrame(apple[\"Volume\"].shift(18)).rename(columns={\"Volume\":\"y_lag_18\"})\nX4 = X4.fillna(0.0)\n\nX5 = pd.DataFrame(apple[\"Volume\"].shift(19)).rename(columns={\"Volume\":\"y_lag_19\"})\nX5 = X5.fillna(0.0)\n\nX = pd.concat([X1, X2, X3, X4, X5], axis=1)\n\ny = apple[\"Volume\"].copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:36:11.265757Z","iopub.execute_input":"2022-03-10T20:36:11.266323Z","iopub.status.idle":"2022-03-10T20:36:11.283307Z","shell.execute_reply.started":"2022-03-10T20:36:11.266287Z","shell.execute_reply":"2022-03-10T20:36:11.282508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data splits\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state= 101)\n\n# Fit and predict\nmodel = LinearRegression()  # `fit_intercept=True` since we didn't use DeterministicProcess\n\nmodel.fit(X_train, y_train)\ny_pred = pd.Series(model.predict(X_train), index=y_train.index)\ny_fore = pd.Series(model.predict(X_test), index=y_test.index)\nprint(f'Model train accuracy: {model.score(X_train, y_train)*100:.3f}%')\nprint(f'Model test accuracy: {model.score(X_test, y_test)*100:.3f}%')\nprint(f'Model train MAE: {mae(y_pred,y_train):.3f}')\nprint(f'Model train RMSE: {mse(y_pred,y_train, squared=False):.3f}')\nprint(f'Model test MAE: {mae(y_fore,y_test):.3f}')\nprint(f'Model test RMSE: {mse(y_fore,y_test, squared=False):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:36:14.044005Z","iopub.execute_input":"2022-03-10T20:36:14.044741Z","iopub.status.idle":"2022-03-10T20:36:14.102518Z","shell.execute_reply.started":"2022-03-10T20:36:14.044699Z","shell.execute_reply":"2022-03-10T20:36:14.100281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.plot(**plot_params)\ny_test.plot(**plot_params)\ny_pred.plot( )\ny_fore.plot( )","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:36:24.678357Z","iopub.execute_input":"2022-03-10T20:36:24.67867Z","iopub.status.idle":"2022-03-10T20:36:25.218957Z","shell.execute_reply.started":"2022-03-10T20:36:24.678639Z","shell.execute_reply":"2022-03-10T20:36:25.217869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Hybrid model (Linear Regression + XGBoost) for apple[\"Volume\"]:** \n\nmodel_1 = Linear Regression and DeterministicProcess as features to find trend \n\nmodel_2 = XGBoost and Lag features ","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:41:15.663747Z","iopub.execute_input":"2022-03-10T20:41:15.664001Z","iopub.status.idle":"2022-03-10T20:41:15.673513Z","shell.execute_reply.started":"2022-03-10T20:41:15.663975Z","shell.execute_reply":"2022-03-10T20:41:15.67279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Train and predict with first model (LinearRegression) \n# a simple (usually linear) learning algorithm\n# model_1.fit(X_train_1, y_train)\n# y_pred_1 = model_1.predict(X_train)\n\ny = apple[\"Volume\"].copy()\n\ndp = DeterministicProcess(\n    index=y.index,  # dates from the training data\n    constant=True,  # the intercept\n    order=1,        # linear trend\n    drop=True,      # drop terms to avoid collinearity\n)\nX = dp.in_sample()  # features for the training data for the first model\n\n# It will be easier for us later if we\n# split the date index instead of the dataframe directly.\nidx_train, idx_test = train_test_split(y.index, test_size=0.2, shuffle=False)\nX_train, X_test = X.loc[idx_train, :], X.loc[idx_test, :]\ny_train, y_test = y.loc[idx_train], y.loc[idx_test]\n\n# Fit trend model\nmodel = LinearRegression(fit_intercept=False) # `fit_intercept=False` since we did use DeterministicProcess with constant=True \nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_fit = pd.Series(\n    model.predict(X_train),\n    index=y_train.index,\n    )\ny_pred = pd.Series(\n    model.predict(X_test),\n    index=y_test.index,\n    )\n\n# Plot\naxs = y_train.plot(color='0.25', subplots=True, sharex=True)\naxs = y_test.plot(color='0.25', subplots=True, sharex=True, ax=axs)\naxs = y_fit.plot(color='C0', subplots=True, sharex=True, ax=axs)\naxs = y_pred.plot(color='C3', subplots=True, sharex=True, ax=axs)\nfor ax in axs: ax.legend([])\n_ = plt.suptitle(\"Volume Trend\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:54:20.684114Z","iopub.execute_input":"2022-03-10T20:54:20.684391Z","iopub.status.idle":"2022-03-10T20:54:21.246735Z","shell.execute_reply.started":"2022-03-10T20:54:20.684364Z","shell.execute_reply":"2022-03-10T20:54:21.245873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Train and predict with second model on residuals\n# model_2.fit(X_train_2, y_train - y_pred_1)\n# y_pred_2 = model_2.predict(X_train_2)\n\n\n#X = make_lags(apple[\"Volume\"], lags=11)\n#X = X.fillna(0.0)\n\n# Create X for the second ML model \nX1 = make_lags(apple[\"Volume\"], lags=11)\nX1 = X1.fillna(0.0)\n\nX2 = pd.DataFrame(apple[\"Volume\"].shift(13)).rename(columns={\"Volume\":\"y_lag_13\"})\nX2 = X2.fillna(0.0)\n\nX3 = pd.DataFrame(apple[\"Volume\"].shift(15)).rename(columns={\"Volume\":\"y_lag_15\"})\nX3 = X3.fillna(0.0)\n\nX4 = pd.DataFrame(apple[\"Volume\"].shift(18)).rename(columns={\"Volume\":\"y_lag_18\"})\nX4 = X4.fillna(0.0)\n\nX5 = pd.DataFrame(apple[\"Volume\"].shift(19)).rename(columns={\"Volume\":\"y_lag_19\"})\nX5 = X5.fillna(0.0)\n\nX = pd.concat([X1, X2, X3, X4, X5], axis=1)\n\n\n# Create splits\nX_train, X_test = X.loc[idx_train, :], X.loc[idx_test, :]\n# y_train, y_test = y.loc[idx_train], y.loc[idx_test]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:54:32.472409Z","iopub.execute_input":"2022-03-10T20:54:32.473169Z","iopub.status.idle":"2022-03-10T20:54:32.49088Z","shell.execute_reply.started":"2022-03-10T20:54:32.473135Z","shell.execute_reply":"2022-03-10T20:54:32.490276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Train and predict with second model (a complex, non-linear learner like GBDTs or a deep neural net) \n# on residuals\n# model_2.fit(X_train_2, y_train - y_pred_1)\n# y_pred_2 = model_2.predict(X_train_2)\n\n# Create residuals (the collection of detrended series) from the training set\ny_resid = y_train - y_fit\n\n# Train XGBoost on the residuals\nxgb = XGBRegressor()\nxgb.fit(X_train, y_resid)\n\n# Add the predicted residuals onto the predicted trends\ny_fit_boosted = xgb.predict(X_train) + y_fit\ny_pred_boosted = xgb.predict(X_test) + y_pred","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:54:35.090999Z","iopub.execute_input":"2022-03-10T20:54:35.09153Z","iopub.status.idle":"2022-03-10T20:54:35.917339Z","shell.execute_reply.started":"2022-03-10T20:54:35.091497Z","shell.execute_reply":"2022-03-10T20:54:35.916678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Model train MAE: {mae(y_fit_boosted,y_train):.3f}')\nprint(f'Model test MAE: {mae(y_pred_boosted,y_test):.3f}')\n\nprint(f'Model train RMSE: {mse(y_fit_boosted,y_train, squared=False):.3f}')\nprint(f'Model test RMSE: {mse(y_pred_boosted,y_test, squared=False):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:54:39.674352Z","iopub.execute_input":"2022-03-10T20:54:39.674897Z","iopub.status.idle":"2022-03-10T20:54:39.682719Z","shell.execute_reply.started":"2022-03-10T20:54:39.674863Z","shell.execute_reply":"2022-03-10T20:54:39.681868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"axs = y_train.plot(color='0.25', figsize=(11, 5), subplots=True, sharex=True, title=['Volume'])\naxs = y_test.plot(color='0.25', subplots=True, sharex=True, ax=axs)\naxs = y_fit_boosted.plot(color='C0', subplots=True, sharex=True, ax=axs)\naxs = y_pred_boosted.plot(color='C3', subplots=True, sharex=True, ax=axs)\nfor ax in axs: ax.legend([])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:58:14.840909Z","iopub.execute_input":"2022-03-10T20:58:14.841565Z","iopub.status.idle":"2022-03-10T20:58:15.424623Z","shell.execute_reply.started":"2022-03-10T20:58:14.841521Z","shell.execute_reply":"2022-03-10T20:58:15.423762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Time series decomposition to:** \n\nTrend - Consistent upwards or downwards slope of a time series\n\nSeasonality - Clear periodic pattern of a time series\n\nNoise - Outliers or missing values","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\n# Period of the series. Must be used if x is not a pandas object or if the index of x does not have a frequency. Overrides default periodicity of x if x is a pandas object with a timeseries index.\ndecomposed_oracle_close = seasonal_decompose(apple[\"Close\"], period=180) \ndecomposed_oracle_close.plot( )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:58:41.645353Z","iopub.execute_input":"2022-03-10T20:58:41.646091Z","iopub.status.idle":"2022-03-10T20:58:42.448561Z","shell.execute_reply.started":"2022-03-10T20:58:41.646053Z","shell.execute_reply":"2022-03-10T20:58:42.447234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Seasonality:** (text is taken from https://www.kaggle.com/ryanholbrook/seasonality)\n\nA time series exhibits seasonality whenever there is a regular, periodic change in the mean of the series.\n\nTwo kinds of features that model seasonality:\n\nIndicators: for a short season with few observations, like a weekly season of daily observations.\nSeasonal indicators are binary features, and they are what you get if you treat a seasonal period as a categorical feature and apply one-hot encoding.\n\nFourier features: for a long season with many observations, like an annual season of daily observations. Instead of creating a feature for each date, Fourier features capture the overall shape of the seasonal curve with just a few features.\n\nFourier features are pairs of sine and cosine curves, one pair for each potential frequency in the season starting with the longest.\n\nHow many Fourier pairs should we include in our feature set? We can answer this question with the periodogram. The periodogram tells you the strength of the frequencies in a time series. The value on the y-axis is (a ** 2 + b ** 2) / 2, where a and b are the coefficients of the sine and cosine at that frequency.\n\n","metadata":{}},{"cell_type":"code","source":"# The follwing function is taken from https://www.kaggle.com/ryanholbrook/seasonality\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:58:47.222915Z","iopub.execute_input":"2022-03-10T20:58:47.223194Z","iopub.status.idle":"2022-03-10T20:58:47.230902Z","shell.execute_reply.started":"2022-03-10T20:58:47.223165Z","shell.execute_reply":"2022-03-10T20:58:47.229992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_periodogram(apple.Close)\nplot_periodogram(apple.Volume)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:58:52.266753Z","iopub.execute_input":"2022-03-10T20:58:52.26703Z","iopub.status.idle":"2022-03-10T20:58:53.421203Z","shell.execute_reply.started":"2022-03-10T20:58:52.267002Z","shell.execute_reply":"2022-03-10T20:58:53.417753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Seasonal plots:**","metadata":{}},{"cell_type":"code","source":"# The follwing function is taken from https://www.kaggle.com/ryanholbrook/seasonality\n\ndef seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:59:03.354673Z","iopub.execute_input":"2022-03-10T20:59:03.355101Z","iopub.status.idle":"2022-03-10T20:59:03.363147Z","shell.execute_reply.started":"2022-03-10T20:59:03.355056Z","shell.execute_reply":"2022-03-10T20:59:03.362106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seasonal plots for apple.Close\n\nX = apple.copy()\n# days within a week\nX[\"dayofweek\"] = X.index.dayofweek  # the x-axis (freq)\nX[\"week\"] = X.index.week  # the seasonal period (period)\n\n# days within a month\nX[\"dayofmonth\"] = X.index.day\nX[\"month\"] = X.index.month\n\n# days within a year\nX[\"dayofyear\"] = X.index.dayofyear\nX[\"year\"] = X.index.year\n\nfig, (ax0, ax1, ax2) = plt.subplots(3, 1, figsize=(11, 6))\nseasonal_plot(X, y=\"Close\", period=\"week\", freq=\"dayofweek\", ax=ax0)\nseasonal_plot(X, y=\"Close\", period=\"month\", freq=\"dayofmonth\", ax=ax1);\nseasonal_plot(X, y=\"Close\", period=\"year\", freq=\"dayofyear\", ax=ax2);\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:59:11.469743Z","iopub.execute_input":"2022-03-10T20:59:11.469987Z","iopub.status.idle":"2022-03-10T20:59:26.773053Z","shell.execute_reply.started":"2022-03-10T20:59:11.469961Z","shell.execute_reply":"2022-03-10T20:59:26.772453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seasonal plots for apple.Volume\n\nX = apple.copy()\n# days within a week\nX[\"dayofweek\"] = X.index.dayofweek  # the x-axis (freq)\nX[\"week\"] = X.index.week  # the seasonal period (period)\n\n# days within a month\nX[\"dayofmonth\"] = X.index.day\nX[\"month\"] = X.index.month\n\n# days within a year\nX[\"dayofyear\"] = X.index.dayofyear\nX[\"year\"] = X.index.year\n\nfig, (ax0, ax1, ax2) = plt.subplots(3, 1, figsize=(11, 6))\nseasonal_plot(X, y=\"Volume\", period=\"week\", freq=\"dayofweek\", ax=ax0)\nseasonal_plot(X, y=\"Volume\", period=\"month\", freq=\"dayofmonth\", ax=ax1);\nseasonal_plot(X, y=\"Volume\", period=\"year\", freq=\"dayofyear\", ax=ax2);\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:00:11.169018Z","iopub.execute_input":"2022-03-10T21:00:11.169904Z","iopub.status.idle":"2022-03-10T21:00:26.67493Z","shell.execute_reply.started":"2022-03-10T21:00:11.169852Z","shell.execute_reply":"2022-03-10T21:00:26.674176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear Regression and concatenation of lag features and deterministic process as features to predict apple[\"Close\"]**","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfourier = CalendarFourier(freq=\"A\", order=3)  # 3 sin/cos pairs for \"A\"nnual seasonality\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:22.266839Z","iopub.execute_input":"2022-03-10T21:13:22.267108Z","iopub.status.idle":"2022-03-10T21:13:22.271393Z","shell.execute_reply.started":"2022-03-10T21:13:22.267077Z","shell.execute_reply":"2022-03-10T21:13:22.270809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apple.index","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:25.228179Z","iopub.execute_input":"2022-03-10T21:13:25.228912Z","iopub.status.idle":"2022-03-10T21:13:25.235128Z","shell.execute_reply.started":"2022-03-10T21:13:25.228876Z","shell.execute_reply":"2022-03-10T21:13:25.234231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we change timestamp to period in order index to have a frequency\n#apple.index = apple.index.to_period(\"D\")\n#apple.index","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:05:48.172853Z","iopub.execute_input":"2022-03-10T21:05:48.173227Z","iopub.status.idle":"2022-03-10T21:05:48.181145Z","shell.execute_reply.started":"2022-03-10T21:05:48.173198Z","shell.execute_reply":"2022-03-10T21:05:48.180096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#apple.index = apple.index.to_timestamp(\"D\")\n#apple.index","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:05:56.218732Z","iopub.execute_input":"2022-03-10T21:05:56.218999Z","iopub.status.idle":"2022-03-10T21:05:56.227836Z","shell.execute_reply.started":"2022-03-10T21:05:56.21897Z","shell.execute_reply":"2022-03-10T21:05:56.227284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp = DeterministicProcess(\n    index=apple.index,\n    constant=True,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    #seasonal=True,              # seasonality (indicators). \n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\n# Note If period in DeterministicProcess not provided, \n# for the period of the seasonal (or fourier) components, freq is read from index if available.\n# freq of index is \"D\" here (apple.index = apple.index.to_period(\"D\")). \n\n\nX_t_s = dp.in_sample()  # create features for dates in apple.index","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:33.807122Z","iopub.execute_input":"2022-03-10T21:13:33.807962Z","iopub.status.idle":"2022-03-10T21:13:33.823303Z","shell.execute_reply.started":"2022-03-10T21:13:33.807926Z","shell.execute_reply":"2022-03-10T21:13:33.822209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_t_s.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:38.137Z","iopub.execute_input":"2022-03-10T21:13:38.137594Z","iopub.status.idle":"2022-03-10T21:13:38.15599Z","shell.execute_reply.started":"2022-03-10T21:13:38.137543Z","shell.execute_reply":"2022-03-10T21:13:38.155327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_c = make_lags(apple[\"Close\"], lags=1)\nX_c = X_c.fillna(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:41.379814Z","iopub.execute_input":"2022-03-10T21:13:41.380249Z","iopub.status.idle":"2022-03-10T21:13:41.387463Z","shell.execute_reply.started":"2022-03-10T21:13:41.380206Z","shell.execute_reply":"2022-03-10T21:13:41.386648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.concat([X_t_s, X_c], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:43.55135Z","iopub.execute_input":"2022-03-10T21:13:43.551779Z","iopub.status.idle":"2022-03-10T21:13:43.555901Z","shell.execute_reply.started":"2022-03-10T21:13:43.551747Z","shell.execute_reply":"2022-03-10T21:13:43.555322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create target series and data splits\ny = apple[\"Close\"].copy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Fit and predict\nmodel = LinearRegression(fit_intercept=False)  # `fit_intercept=False` since we uses DeterministicProcess with constant=True\nmodel.fit(X_train, y_train)\ny_pred = pd.Series(model.predict(X_train), index=y_train.index)\ny_fore = pd.Series(model.predict(X_test), index=y_test.index)\nprint(f'Model train accuracy: {model.score(X_train, y_train)*100:.3f}%')\nprint(f'Model test accuracy: {model.score(X_test, y_test)*100:.3f}%')\n\nprint(f'Model train MAE: {mae(y_pred,y_train):.3f}')\nprint(f'Model train RMSE: {mse(y_pred,y_train, squared=False):.3f}')\nprint(f'Model test MAE: {mae(y_fore,y_test):.3f}')\nprint(f'Model test RMSE: {mse(y_fore,y_test, squared=False):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:47.507883Z","iopub.execute_input":"2022-03-10T21:13:47.508731Z","iopub.status.idle":"2022-03-10T21:13:47.540424Z","shell.execute_reply.started":"2022-03-10T21:13:47.508676Z","shell.execute_reply":"2022-03-10T21:13:47.539539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.plot(**plot_params)\ny_test.plot(**plot_params)\ny_pred.plot( )\ny_fore.plot( )","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:51.344435Z","iopub.execute_input":"2022-03-10T21:13:51.344746Z","iopub.status.idle":"2022-03-10T21:13:51.826091Z","shell.execute_reply.started":"2022-03-10T21:13:51.344716Z","shell.execute_reply":"2022-03-10T21:13:51.825078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear Regression and DeterministicProcess as features to predict trend for apple[\"Close\"]**","metadata":{}},{"cell_type":"code","source":"apple.index","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:13:57.239692Z","iopub.execute_input":"2022-03-10T21:13:57.24009Z","iopub.status.idle":"2022-03-10T21:13:57.247328Z","shell.execute_reply.started":"2022-03-10T21:13:57.240059Z","shell.execute_reply":"2022-03-10T21:13:57.246506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apple.index = apple.index.to_period(\"D\")\napple.index","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:20:55.558708Z","iopub.execute_input":"2022-03-10T21:20:55.558975Z","iopub.status.idle":"2022-03-10T21:20:55.567966Z","shell.execute_reply.started":"2022-03-10T21:20:55.558948Z","shell.execute_reply":"2022-03-10T21:20:55.567001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = apple[\"Close\"].copy()\n\nfourier = CalendarFourier(freq=\"A\", order=3)  # 3 sin/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=apple.index,\n    constant=True,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    #seasonal=True,              # seasonality (indicators). \n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\nX = dp.in_sample()  # create features for dates in apple.index\n\nmodel = LinearRegression(fit_intercept=False) # `fit_intercept=False` since we uses DeterministicProcess with constant=True\nmodel.fit(X, y)\ny_pred = pd.Series(model.predict(X), index=y.index)\n\nX_fore = dp.out_of_sample(steps=90)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(color='0.25', style='.', title=\"Apple Close - Trend-Seasonal Forecast\")\nax = y_pred.plot(ax=ax, label=\"Trend-Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Trend-Seasonal Forecast\", color='C3')\n_ = ax.legend()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:24:23.112857Z","iopub.execute_input":"2022-03-10T21:24:23.113324Z","iopub.status.idle":"2022-03-10T21:24:23.713512Z","shell.execute_reply.started":"2022-03-10T21:24:23.113288Z","shell.execute_reply":"2022-03-10T21:24:23.712706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Hybrid model (Linear Regression + XGBoost) for apple[[\"Close\", \"Volume\"]]:**","metadata":{}},{"cell_type":"code","source":"# 1. Train and predict with first model (LinearRegression) \n# a simple (usually linear) learning algorithm\n# model_1.fit(X_train_1, y_train)\n# y_pred_1 = model_1.predict(X_train)\n\ny = apple[[\"Close\", \"Volume\"]].copy()\n\n# Create trend features\ndp = DeterministicProcess(\n    index=y.index,  # dates from the training data\n    constant=True,  # the intercept\n    order=1,        # linear trend\n    drop=True,      # drop terms to avoid collinearity\n)\nX = dp.in_sample()  # features for the training data\n\n# It will be easier for us later if we\n# split the date index instead of the dataframe directly.\nidx_train, idx_test = train_test_split(y.index, test_size=0.2, shuffle=False)\nX_train, X_test = X.loc[idx_train, :], X.loc[idx_test, :]\ny_train, y_test = y.loc[idx_train], y.loc[idx_test]\n\n# Fit trend model\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_fit = pd.DataFrame(\n    model.predict(X_train),\n    index=y_train.index,\n    columns=y_train.columns,\n)\ny_pred = pd.DataFrame(\n    model.predict(X_test),\n    index=y_test.index,\n    columns=y_test.columns,\n)\n\n# Plot\naxs = y_train.plot(color='0.25', subplots=True, sharex=True)\naxs = y_test.plot(color='0.25', subplots=True, sharex=True, ax=axs)\naxs = y_fit.plot(color='C0', subplots=True, sharex=True, ax=axs)\naxs = y_pred.plot(color='C3', subplots=True, sharex=True, ax=axs)\nfor ax in axs: ax.legend([])\n_ = plt.suptitle(\"Trends\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:28:16.568155Z","iopub.execute_input":"2022-03-10T21:28:16.568467Z","iopub.status.idle":"2022-03-10T21:28:17.315696Z","shell.execute_reply.started":"2022-03-10T21:28:16.568417Z","shell.execute_reply":"2022-03-10T21:28:17.314509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The `stack` method converts column labels to row labels, pivoting from wide format to long\ndf = apple[[\"Close\", \"Volume\"]].copy()\ndf = pd.concat({'Value': df}, names=[None, 'Variables'], axis=1)\nX = df.stack()  # pivot dataset wide to long\ndisplay(X.head())\ny = X.pop('Value')  # grab target series\ndisplay(X.head())\ndisplay(y.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:28:23.612399Z","iopub.execute_input":"2022-03-10T21:28:23.61296Z","iopub.status.idle":"2022-03-10T21:28:23.646026Z","shell.execute_reply.started":"2022-03-10T21:28:23.612902Z","shell.execute_reply":"2022-03-10T21:28:23.645411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn row labels into categorical feature columns with a label encoding\nX = X.reset_index('Variables')\ndisplay(X.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:28:30.445147Z","iopub.execute_input":"2022-03-10T21:28:30.445543Z","iopub.status.idle":"2022-03-10T21:28:30.455611Z","shell.execute_reply.started":"2022-03-10T21:28:30.445513Z","shell.execute_reply":"2022-03-10T21:28:30.454778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label encoding for 'Variables' feature\nfor colname in X.select_dtypes([\"object\", \"category\"]):\n    X[colname], _ = X[colname].factorize()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:28:34.206697Z","iopub.execute_input":"2022-03-10T21:28:34.206969Z","iopub.status.idle":"2022-03-10T21:28:34.214251Z","shell.execute_reply.started":"2022-03-10T21:28:34.206941Z","shell.execute_reply":"2022-03-10T21:28:34.213219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(X.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:28:37.601046Z","iopub.execute_input":"2022-03-10T21:28:37.601553Z","iopub.status.idle":"2022-03-10T21:28:37.610221Z","shell.execute_reply.started":"2022-03-10T21:28:37.601509Z","shell.execute_reply":"2022-03-10T21:28:37.609294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label encoding for annual seasonality\n#X[\"Month\"] = X.index.month  # values are 1, 2, ..., 12\n#X[\"Year\"] = X.index.year\n\n# Create splits\n#X_train, X_test = pd.concat([X.loc[idx_train, :], X_c.loc[idx_train, :]], axis=1), pd.concat([X.loc[idx_test, :], X_c.loc[idx_test, :]], axis=1)\n\nX_train, X_test = X.loc[idx_train, :], X.loc[idx_test, :]\ny_train, y_test = y.loc[idx_train], y.loc[idx_test]\ndisplay(X_train.head())\ndisplay(y_train.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:29:05.357489Z","iopub.execute_input":"2022-03-10T21:29:05.357749Z","iopub.status.idle":"2022-03-10T21:29:05.387894Z","shell.execute_reply.started":"2022-03-10T21:29:05.357721Z","shell.execute_reply":"2022-03-10T21:29:05.386986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_fit.stack().head()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T03:09:18.508731Z","iopub.execute_input":"2022-03-08T03:09:18.50903Z","iopub.status.idle":"2022-03-08T03:09:18.523232Z","shell.execute_reply.started":"2022-03-08T03:09:18.508985Z","shell.execute_reply":"2022-03-08T03:09:18.522322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_resid = y_train - y_fit.stack()\n# y_resid.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T03:09:20.672532Z","iopub.execute_input":"2022-03-08T03:09:20.673008Z","iopub.status.idle":"2022-03-08T03:09:20.687173Z","shell.execute_reply.started":"2022-03-08T03:09:20.672974Z","shell.execute_reply":"2022-03-08T03:09:20.686158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\n# Pivot wide to long (stack) and convert DataFrame to Series (squeeze)\ny_fit = y_fit.stack().squeeze()  # trend from training set\ny_pred = y_pred.stack().squeeze()  # trend from test set\n\n# Create residuals (the collection of detrended series) from the training set\ny_resid = y_train - y_fit\n\n# Train XGBoost on the residuals\nxgb = XGBRegressor()\nxgb.fit(X_train, y_resid)\n\n# Add the predicted residuals onto the predicted trends\ny_fit_boosted = xgb.predict(X_train) + y_fit\ny_pred_boosted = xgb.predict(X_test) + y_pred","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:29:13.60056Z","iopub.execute_input":"2022-03-10T21:29:13.601424Z","iopub.status.idle":"2022-03-10T21:29:13.886549Z","shell.execute_reply.started":"2022-03-10T21:29:13.601383Z","shell.execute_reply":"2022-03-10T21:29:13.885876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"axs = y_train.unstack(['Variables']).plot(\n    color='0.25', figsize=(11, 5), subplots=True, sharex=True,\n    title=['Close', 'Volume'],\n)\naxs = y_test.unstack(['Variables']).plot(color='0.25', subplots=True, sharex=True, ax=axs)\n\naxs = y_fit_boosted.unstack( ).plot(color='C0', subplots=True, sharex=True, ax=axs)\n\naxs = y_pred_boosted.unstack( ).plot(color='C3', subplots=True, sharex=True, ax=axs)\nfor ax in axs: ax.legend([])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:29:20.059499Z","iopub.execute_input":"2022-03-10T21:29:20.059782Z","iopub.status.idle":"2022-03-10T21:29:20.679995Z","shell.execute_reply.started":"2022-03-10T21:29:20.059751Z","shell.execute_reply":"2022-03-10T21:29:20.67914Z"},"trusted":true},"execution_count":null,"outputs":[]}]}